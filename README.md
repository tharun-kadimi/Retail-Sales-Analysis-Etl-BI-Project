# Retail-Sales-Analysis-Etl-BI-Project
Got it ğŸ‘ Since you only want the **README to explain the code (not dashboards, insights, etc.)**, hereâ€™s a **clean, code-focused README.md** draft you can add to your project folder:

---

# ğŸ› ï¸ Retail Sales ETL Project

## ğŸ“Œ Overview

This project implements an **ETL pipeline** for retail sales data using **Python** and **Oracle SQL**. The workflow extracts raw data from CSV files, transforms it using Pandas, and loads it into a staging schema and final **Data Warehouse (DW)** schema.

---

## âš™ï¸ Tech Stack

* **Python 3.x**

  * `pandas` â†’ Data extraction & transformation
  * `numpy` â†’ Handling missing values & calculations
  * `sqlalchemy` â†’ Database connectivity
  * `cx_Oracle` â†’ Oracle DB driver
* **Oracle SQL** â†’ Staging & Data Warehouse schema

---

## ğŸ“‚ Project Structure

```
Retail-Sales-ETL/
â”‚
â”œâ”€â”€ data/               # Raw input CSV files
â”‚   â”œâ”€â”€ customers.csv
â”‚   â”œâ”€â”€ products.csv
â”‚   â”œâ”€â”€ sales.csv
â”‚   â””â”€â”€ stores.csv
â”‚
â”œâ”€â”€ etl/
|  â”œâ”€â”€ .env
|  â”œâ”€â”€ config.ini
|  â”œâ”€â”€ etl.py                # Main ETL script (Python)
|  â””â”€â”€hybrid_settings.py            
â”‚
â”œâ”€â”€ sql/                # SQL scripts
â”‚   â”œâ”€â”€ ddl_orcale.sql
â”‚   â”œâ”€â”€ create_dw.sql
â”‚   â””â”€â”€ load_dw.sql
â”‚
â”œâ”€â”€ bi/
â”‚   â”œâ”€â”€ bi_report.pbix
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ sql_query.docx
â”‚   â””â”€â”€ project_docs.docx
â”œâ”€â”€ Scripts/
|   â””â”€â”€ generate_data.py        #generates required data for project 
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md           # Project documentation
```

---

## ğŸ”„ ETL Script Description (`etl.py`)

The **ETL script** (`etl.py`) performs the following steps:

### 1. **Import Modules**

* `pandas`, `numpy` â†’ Data wrangling
* `sqlalchemy` â†’ DB connection
* `logging` â†’ Process logging

### 2. **Database Connection**

```python
engine = create_engine(
    "oracle+cx_oracle://<username>:<password>@<host>:<port>/<service_name>"
)
```

### 3. **Extraction**

* Reads CSV files into Pandas DataFrames:

```python
df_sales = pd.read_csv("data/sales.csv")
df_products = pd.read_csv("data/products.csv")
df_customers = pd.read_csv("data/customers.csv")
df_stores = pd.read_csv("data/stores.csv")
```

### 4. **Transformation**

* Handle missing values (`fillna`, `dropna`).
* Convert columns to correct datatypes (e.g., dates, numerics).
* Add derived columns:

  * `Revenue = Quantity Ã— Unit_Price`
  * `Profit = Revenue â€“ Cost`

### 5. **Loading**

* Load DataFrames into **Staging Tables**:

```python
df_sales.to_sql("stg_sales", engine, if_exists="replace", index=False)
```

* Transform & insert into **DW Star Schema** (`FactSales`, `DimProduct`, `DimCustomer`, etc.).

### 6. **Logging**

* All steps are logged into a `etl.log` file for monitoring success/failure.

---

## ğŸš€ How to Run the Code

1. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```
2. Update **DB credentials** inside `etl.py`.
3. Run ETL script:

   ```bash
   python etl.py
   ```
4. Execute SQL scripts from `/sql/` in Oracle DB to create schema & relations.

---

## ğŸ“œ Deliverables

* `etl.py` â†’ Python ETL script
* `/sql/` â†’ Schema creation & load scripts
* `/data/` â†’ Raw input CSV files
* `README.md` â†’ Code documentation

---
